# 데이터 분석 사례 Case Study 
- 분석 사례를 많이 보는 것은 중요하다. Reference로 활용하기에 좋고, 기존 방법을 변형하여 사용하기도 좋다. 분석할 때 어떤 방법 활용해서 어떻게 시작할지조차 막막하기 마련인데 사례를 많이 알면 어느정도 해소되지 않을까.

|num|제목|링크|설명|
|:---:|:---:|:---:|:---:| 
|1|데이터 분석 시작하기 |[link](https://www.slideshare.net/leoyang991/ss-90038927)|네웹 인턴할 때 데이터 분석 과정 관련해서 재밌게 봤던 자료|
|2|포스트 코로나 시대 Insight|[link](https://dacon.io/competitions/official/235618/codeshare/1448)|너무너무 재밌었다. 카드 소비 데이터를 기준으로 업종별 결제건수를 Clustering하고, 군집별로 외부데이터 활용하며 설명해 놨다. |
|3|코로나19와의 전쟁에서 생명 구하기 - '사망'에 대한 insights 도출|[link](https://dacon.io/codeshare/949)||
|4|카카오 엔터프라이즈, 스마트 홈트 - 칼로리·영양 정보 알려주는 식단 카메라… 딥러닝 기술로 사진 속 1000여 종 음식 구분|[link](https://magazine.hankyung.com/business/article/2020110301301000471)||
|5|비씨카드 '소상공인 업종별 단골고객을 정의하고 매출 등의 영향을 분석하는 AI' |[link](https://www.youtube.com/watch?v=WvvKBmTsPTY)||


# 기타 느낀점.
## 2. 포스트 코로나 시대 Insight  
- Trend가 존재하는 군집화 방법에 대해 알았다. 많이 사용되는 방법인지는 잘 모르겠으나 참신하게 다가왔다.
- 시계열 데이터 분해 방법으로 Trend(추세) + Seasonal(계절성) + Random(잔차) 로 나누고, Trend를 추출한 후 :point_right: Trend를 기준으로 Corr 계산한다.  :point_right: 이렇게 구한 Corr을 바탕으로  계층 군집(Hierarchical cluster)을 ward연결법으로 시행하는 방법.
- 참고링크 : https://eat-toast.tistory.com/15
- 관련해서 시간 여유 있을 때 아래 분석도 볼 것이다


## 3. 코로나19와의 전쟁에서 생명 구하기
- 사용한 방법론은 K-means 클러스터링 사용. 아래와 같은 변수 변환 및 사용. 
- 활용한 방법론은 많진 않지만 행동특성을 잡고 변수로 어떻게 만들것인가에 대한 내용이 인상깊었고 스토리 라인이 좋았다.

1) 행동 특성을 다음의 4가지 고려함
감염 경로 유형 (Infection route), 유동성 (Mobility level), 접촉 정도 (Number of contacts), 확진받기까지 걸린 시간 (Diagnosis time)

2) 위 변수 생성을 위해 아래와 같이 변수 생성
numeric : 유동성 특성(essential/non-essential), 확진받기까지 걸린 시간(days), 접촉 정도(contact_number)
categorical 변수 : 감염 경로 유형 (Infection route) 
- categorical 변수는 one-hot 인코딩으로 numeric변환함.

3) PCA로 차원축소. (PCA1, PCA2) 선정

4) 생성된 PCA 가지고 Clustering 하고 아래와 같이 유형 나눔.
첫번째 유형(Hypermobile & hypersocial unknowns)은 모두 감염 경로가 알려지지 않은 확진자
두번째 유형(Moderate groupies)은 모두 집단 감염자들이며
세번째 유형(Social minimalists)은 모두 개인적으로 감염되었고
네번째 유형(Overseas non-essentialists)은 모두 해외 유입

이렇게 나누고 1)에서와 같은 행동특성별로 그룹 특성 살펴보고 추가적으로는 유형 별 사망자/회복자의 분포 나눠 살펴봄. 


## 4. 칼로리·영양 정보 알려주는 식단 카메라 
- 카카오 VX가 만든 ‘스마트홈트’로 사진 속 음식의 이름과 칼로리를 자동으로 입력해 주는 식단 카메라 기능을 제공하고 있음. 만든 과정은 아래 정리
##### 레이블 스무딩
- Classification에서는 1 또는 0으로 값이 주어지는데 이 라벨링이 잘못 수 있어서 smooth하게 부여하는 것을 의미함. 
- 오분류된 데이터는 추가적으로 정규화 과정에도 도움을 줄 수 있어서 교정 효과 뿐 아니라 일반화 가능성을 높여줄 수 있음. 

##### 데이터 어그멘테이션
- 이미지 데이터를 인위적으로 뒤집거나 자르는 방식으로 데이터 양 확보하는 방법.

##### 이외에 기억남는것.
- TTA(Test-Time-Augmentation, 테스트 단계에서의 어그멘테이션)
- 음식 아닌데 음식으로 판단하는 것 방지하기 위해서 1) 음식인지 아닌지 분류 후 -> 2) 음식분류기 활용함.

## 5. 비씨카드 '소상공인 업종별 단골고객을 정의하고 매출 등의 영향을 분석하는 AI'
- 재밌었당
- 역시 분석뿐 아니라 기대효과, 비즈니스 효과가 중요하다는 것을 느꼈다. 심사위원님들 질문이 주로 그랬다. 

- 소상공인은 외부 효과의 영향이 많은데, control할 수 있는 정보는?
-> 경제지수 활용한다? 

*단골이란 무엇인가? 의 정의
- 사람마다 주기성이 다르다. 

- 기술과 비즈니스의 

###### 의미있었던 말
- 소상공인 입장에서는 매출만 올렸음 좋겠는 것임. 따라서 어떻게하면 매출을 올릴 수 있을까 하는 기술의 활용성 위주로 설명할 수 있어야 함.
- 즉 확실한 목표가 있어야 하고 실질적인 이점이 있어야 한다.

## 6. 공공 빅데이터 분석 공모전
- 청중평가단(100)에 참가해서 100명중 한명으로 있었다 ! 
#### 행정안전부 인프라구축과 
- 조세행정에 데이터 분석을 활용함.
- 제대로 세금을 냈는지 확인하는 데 있어 분석을 활용함. 
- 납부 가능성 높은 사람들은 우편보다 문자나 전화 등 간단하게 확인할 수 있도록 함.

#### 김해시청 
- **치매 위험도 예측.** 
- 가구 유형, 라이프스타일이 중요했다.
- 아래처럼 분류가 가능했다는 점에서 활용가능성이 높아서 좋았다.
    - 고위험군 : 건강 챙기지 않는 75 이상 노부부, 80세 이상 독거노인
    - 저위험군 : 소비력/ 사회력있는 가정 부양, 사회적 활동 하는 노인
- 잠재 위험 지역도 선정했다는 게 좋았다.
- 근데 용역을 줘서 분석한거라고 하심. 

#### 서울특별시 성동구청
- 스마트 횡단보도 입지지수 = 횡당보도 수요지수 +교통사고 위험지수 + 교통약자 포용지수
- '참여형 데이터' 가 인상깊었다.
  - 공공데이터 섬세함이 떨어진다. 주민 체감 데이터를 수집했다. 위험하다고 느낀 지점 식별, 사고가 날뻔한 데이터 식별 데이터를 결합해서 활용함.
- 지수개발이다보니까 평가 지표? 다른 지역에 비해서 이 지역이 어떤 점이 다른 지점에 비해 잘 선정되었나와 같은 내용이 

`궁금증`
- 참여형 데이터를 산출하는 데 있어서 어른에 비해 아이들이 위험한 지역을 왜 가중치를 낮게 주신건지 궁금했다. 어린이들이 위험한 지역도 스마트 횡단보도 입지로 선정하는 것도 중요하지 않을까. 

#### 한국도로공사 
- 가장 분석 알고리즘을 잘 활용한거같았다. 레알 활용하고 있는 Image Classification 
- 차량 훼손 번호판 인식에 대한 문제 해결하기 위한 분석 - 훼손번호판을 분류
- 훼손된 번호판을 가진 차량에 대해서는 엠블럼 인식도 함. (차량이 뭔지, 제조사는 어딘지) 
- 후방 카메라는 

#### 한국소비자원 
- 소비자이슈 조기 감지 서비스 
- 유투브 뒷광고, 코로나 19 마스크 폭리 등 
- 기존 데이터에 소셜 데이터를 활용해야 한다. 

`궁금증`
- 2030은 인스타를 가장 많이쓰는거 같은데 발표 자료에 없어서 궁금했다. 최대한 많이 끌어오는 게 좋을것 같은데..!

#### 컵컵컵
- 분석 재밌었다. 플라스틱 컵 수거함 위치를 선정하는 데 있어서 평가하는 데 있어서 어디가 좋을지 grid 형태로 위치를 예측했다. 
- 인상깊었던 피드백 : 기대효과를 정량화하는 것이 중요하다. 

#### 교통사고 구간 예측 
- SAS공모전에 참여했어서 익숙한 주제였다. 그치만 범위도 너무 넓고, 색다른 부분이 어딘지 모르겠다는 게 아쉬웠다. -> 다른 심사위원님도 언급해주셨다..!
- sharp 분석? - 처음 들어봤는데 이게 뭔지 모르겠다
- 결국 결과가 송파 1위 ?? -> So What ..?? 범위가 너무 넓어서 활용 방안이 모호하다 ..  

#### 헌혈 차 입지선정
- 인상깊었던 질문 : 헌혈을 안하는 이유가 헌혈차량과 접근성이 떨어진다고 가정했는데, 이런 가설을 설정하고 분석을 진행했던 이유는? 
- As-Is -> To-Be 이어지도록 하면 좋았을거같다. 

### 평가단 참여 후기
- 공모전에 여러번 참가했어서 발표자들이 떨려하는 게 이해가 됐다. 그리고 확실히 평가자가 되어보니깐 어떤 점을 집어줘야하는지(?)를 아주아주 조금이나마 알 수 있었다. 
- 첫째로 문제를 제시할 때, 이 문제를 왜 데이터로부터 해결하려고 했는지를 설명할 때, 가정이 합리적이여야 한다. 듣는 사람으로 하여금 데이터로부터 충분히 풀어볼만한 문제일 수 있겠다 라는 생각이 들어야 한다. 
- 둘째로 매끄럽게 이어져야 한다는 것을 알았다. 그리고 쉽게 담아야 한다. (어렵다ㅠㅠ)
- 마지막으로 결론부분이 가장 기억에 많이 남는 만큼, 정리해주는 것이 꼭 필요하다고 느꼈다. 분석 전 과정을 짧게나마 리뷰하는 것이 스토리 라인을 한번 더 각인시키는 효과가 될 것 같다. 실제로 발표가 끝나고 나면 드문 드문 기억나는 것이 일반적이였기 때문이다.

`좋은 경험이였다. 재밌었다` 








